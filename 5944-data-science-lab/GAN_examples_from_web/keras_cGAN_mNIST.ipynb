{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "keras_cGAN_mNIST.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9CVrFUTmcmv"
      },
      "source": [
        "### cGAN_Keras with MNIST data set as sample.\n",
        "Code get from  https://github.com/mabagheri/CGAN/blob/master/cgan_Keras.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUMH1m4i7IyZ",
        "outputId": "3e07efc1-0285-4208-bba8-d50fa61e7c7a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWO7-LWPmcne"
      },
      "source": [
        "#### 1. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_ToRLO4mcnh"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation, Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical, plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo3wdc8cmcnl"
      },
      "source": [
        "#### 2. Define Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXF638Mpmcnm"
      },
      "source": [
        "class CGAN:\n",
        "    def __init__(self, img_width, img_height, n_channels, n_classes):\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.n_channels = n_channels\n",
        "        self.img_shape = (self.img_width, self.img_height, self.n_channels)\n",
        "        self.n_classes = n_classes\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator_model()\n",
        "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
        "                                   optimizer=optimizer,\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim, ))\n",
        "        label = Input(shape=(self.n_classes,))\n",
        "        img = self.generator([noise, label])\n",
        "\n",
        "        # during generator updating,  the discriminator is fixed (will not be updated).\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated image and label as input and determines its validity\n",
        "        validity = self.discriminator([img, label])\n",
        "\n",
        "        self.cgan_model = Model(inputs=[noise, label], outputs=validity) # https://github.com/keras-team/keras/issues/13743\n",
        "        self.cgan_model.compile(loss=['binary_crossentropy'],\n",
        "                                optimizer=optimizer,\n",
        "                                metrics=['accuracy'])\n",
        "\n",
        "        plot_model(self.cgan_model, show_shapes=True, to_file='cgan-adversarial_model.png')\n",
        "        plot_model(self.generator, show_shapes=True, to_file='cgan-generator_model.png')\n",
        "        plot_model(self.discriminator, show_shapes=True, to_file='cgan-discriminator.png')\n",
        "\n",
        "    def build_discriminator_model(self):\n",
        "\n",
        "        model_input = Input(shape=(self.img_width, self.img_height, self.n_channels), name='discriminator_input')\n",
        "\n",
        "        x = model_input\n",
        "\n",
        "        labels = Input(shape=(self.n_classes,))\n",
        "        # labels_embedded = Flatten()(Embedding(self.num_classes, self.latent_dim)(labels))\n",
        "        labels_embedded = Dense(self.img_width * self.img_width)(labels)\n",
        "        labels_embedded = Reshape((self.img_width, self.img_height, self.n_channels))(labels_embedded)\n",
        "\n",
        "        x = concatenate([x, labels_embedded])\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Conv2D(filters=256, kernel_size=5, strides=1, padding='same')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(1)(x)\n",
        "        x = Activation('sigmoid')(x)\n",
        "        # model_input is conditioned by labels\n",
        "        discriminator = Model([model_input, labels], x, name='discriminator')\n",
        "\n",
        "        return discriminator\n",
        "\n",
        "    def build_generator(self):\n",
        "        image_resize = self.img_height // 4\n",
        "\n",
        "        inputs = Input(shape=(self.latent_dim,), name='z_input')\n",
        "        labels = Input(shape=(self.n_classes,), name='class_labels')\n",
        "\n",
        "        x = concatenate([inputs, labels], axis=1)\n",
        "        x = Dense(image_resize * image_resize * 128)(x)\n",
        "        x = Reshape((image_resize, image_resize, 128))(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=32, kernel_size=5, strides=1, padding='same')(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=1, kernel_size=5, strides=1, padding='same')(x)\n",
        "\n",
        "        x = Activation('sigmoid')(x)\n",
        "        # input is conditioned by labels\n",
        "        generator = Model(inputs=[inputs, labels], outputs=x, name='generator') # https://github.com/keras-team/keras/issues/13743\n",
        "        return generator\n",
        "\n",
        "    def train(self, x_train, y_train, epochs=1000, batch_size=128, sample_interval=50):\n",
        "\n",
        "        x_train = np.reshape(x_train, [-1, self.img_width, self.img_height, self.n_channels])\n",
        "        x_train = x_train.astype('float32') / 255\n",
        "\n",
        "        y_train = to_categorical(y_train)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            #  --------------------- Train Discriminator ---------------------\n",
        "            # Select a random half batch of images\n",
        "            idx = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
        "            imgs, labels = x_train[idx], y_train[idx]\n",
        "\n",
        "            # Generate sample noise for generator input\n",
        "            noise = self.generate_noise(\"uniform_noise\", batch_size)\n",
        "\n",
        "            # Generate a half batch of new images\n",
        "            # we can use labels instead of fake_labels; because it is fake for noise\n",
        "            gen_imgs = self.generator.predict([noise, labels])\n",
        "\n",
        "            # --------------------- Train the Discriminator ---------------------\n",
        "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], real)\n",
        "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            #  --------------------- Train the Generator ---------------------\n",
        "            # Condition on labels (random one-hot labels)\n",
        "            fake_labels = np.eye(self.n_classes)[np.random.choice(self.n_classes, batch_size)]\n",
        "\n",
        "            # Train the generator\n",
        "            cgan_loss, acc = self.cgan_model.train_on_batch([noise, fake_labels], real)\n",
        "\n",
        "            # Plot the progress\n",
        "            if (epoch % sample_interval ==0):\n",
        "              print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], cgan_loss))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch) # TO-DOm not working in google colab\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 2, 5\n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[r * c, self.latent_dim])\n",
        "\n",
        "        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
        "        sampled_labels_categorical = to_categorical(sampled_labels)\n",
        "\n",
        "        gen_imgs = self.generator.predict([noise, sampled_labels_categorical])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "                axs[i, j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
        "                axs[i, j].axis('off')\n",
        "                cnt += 1\n",
        "        images_dir = '/content/drive/My Drive/Images'\n",
        "        fig.savefig(f\"{images_dir}/mnist/%d.png\" % epoch, bbox_inches='tight', dpi=200)\n",
        "        plt.close()\n",
        "\n",
        "    def generate_noise(self, type_of_noise, batch_size):\n",
        "        if type_of_noise == \"normal_noise\":\n",
        "            return np.random.normal(0, 1, size=[batch_size, self.latent_dim])\n",
        "\n",
        "        elif type_of_noise == \"uniform_noise\":\n",
        "            return np.random.uniform(-1.0, 1.0, size=[batch_size, self.latent_dim])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr6g_8lemcn1"
      },
      "source": [
        "#### 3. main method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpVK3jFLmcn-",
        "outputId": "f086e8a6-af3b-4d7c-cfa3-b89623b7ab51"
      },
      "source": [
        "(X, y), (_, _) = mnist.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "if X[0].ndim == 3:\n",
        "    img_w, img_h, num_channels = X[0].shape\n",
        "else:\n",
        "    img_w, img_h = X[0].shape\n",
        "    num_channels = 1\n",
        "\n",
        "cgan = CGAN(img_w, img_h, num_channels, num_classes)\n",
        "\n",
        "cgan.train(X, y, epochs=15000, batch_size=32, sample_interval=300)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [D loss: 0.711521, acc.: 6.25%] [G loss: 0.688594]\n",
            "300 [D loss: 0.000308, acc.: 100.00%] [G loss: 0.000003]\n",
            "600 [D loss: 0.059793, acc.: 96.88%] [G loss: 0.044035]\n",
            "900 [D loss: 0.385985, acc.: 82.81%] [G loss: 0.559899]\n",
            "1200 [D loss: 0.546402, acc.: 71.88%] [G loss: 1.062763]\n",
            "1500 [D loss: 0.561641, acc.: 71.88%] [G loss: 1.039736]\n",
            "1800 [D loss: 0.645724, acc.: 57.81%] [G loss: 0.858197]\n",
            "2100 [D loss: 0.662811, acc.: 54.69%] [G loss: 0.885255]\n",
            "2400 [D loss: 0.689138, acc.: 56.25%] [G loss: 0.766497]\n",
            "2700 [D loss: 0.648091, acc.: 64.06%] [G loss: 0.837923]\n",
            "3000 [D loss: 0.676474, acc.: 53.12%] [G loss: 0.829390]\n",
            "3300 [D loss: 0.669853, acc.: 60.94%] [G loss: 0.849549]\n",
            "3600 [D loss: 0.654537, acc.: 57.81%] [G loss: 0.852323]\n",
            "3900 [D loss: 0.673707, acc.: 60.94%] [G loss: 0.827717]\n",
            "4200 [D loss: 0.727941, acc.: 42.19%] [G loss: 0.773100]\n",
            "4500 [D loss: 0.647332, acc.: 62.50%] [G loss: 0.945264]\n",
            "4800 [D loss: 0.686813, acc.: 45.31%] [G loss: 0.739380]\n",
            "5100 [D loss: 0.704681, acc.: 46.88%] [G loss: 0.675124]\n",
            "5400 [D loss: 0.688891, acc.: 51.56%] [G loss: 0.768783]\n",
            "5700 [D loss: 0.699037, acc.: 56.25%] [G loss: 0.751981]\n",
            "6000 [D loss: 0.645359, acc.: 71.88%] [G loss: 0.949956]\n",
            "6300 [D loss: 0.719884, acc.: 43.75%] [G loss: 0.785521]\n",
            "6600 [D loss: 0.670143, acc.: 56.25%] [G loss: 0.740168]\n",
            "6900 [D loss: 0.669075, acc.: 56.25%] [G loss: 0.842718]\n",
            "7200 [D loss: 0.629388, acc.: 65.62%] [G loss: 0.798666]\n",
            "7500 [D loss: 0.676843, acc.: 56.25%] [G loss: 0.761896]\n",
            "7800 [D loss: 0.624594, acc.: 68.75%] [G loss: 0.807387]\n",
            "8100 [D loss: 0.613203, acc.: 73.44%] [G loss: 0.672853]\n",
            "8400 [D loss: 0.654067, acc.: 60.94%] [G loss: 0.868172]\n",
            "8700 [D loss: 0.650020, acc.: 59.38%] [G loss: 0.944091]\n",
            "9000 [D loss: 0.693116, acc.: 51.56%] [G loss: 0.715501]\n",
            "9300 [D loss: 0.655279, acc.: 57.81%] [G loss: 0.832017]\n",
            "9600 [D loss: 0.684374, acc.: 56.25%] [G loss: 0.750164]\n",
            "9900 [D loss: 0.655799, acc.: 56.25%] [G loss: 0.784064]\n",
            "10200 [D loss: 0.687118, acc.: 53.12%] [G loss: 0.777365]\n",
            "10500 [D loss: 0.705093, acc.: 50.00%] [G loss: 0.875052]\n",
            "10800 [D loss: 0.671964, acc.: 54.69%] [G loss: 0.761818]\n",
            "11100 [D loss: 0.645844, acc.: 60.94%] [G loss: 0.874505]\n",
            "11400 [D loss: 0.609919, acc.: 68.75%] [G loss: 0.815971]\n",
            "11700 [D loss: 0.683351, acc.: 59.38%] [G loss: 0.919130]\n",
            "12000 [D loss: 0.594206, acc.: 65.62%] [G loss: 0.801410]\n",
            "12300 [D loss: 0.639267, acc.: 60.94%] [G loss: 0.865757]\n",
            "12600 [D loss: 0.628599, acc.: 57.81%] [G loss: 0.888632]\n",
            "12900 [D loss: 0.640811, acc.: 56.25%] [G loss: 0.799912]\n",
            "13200 [D loss: 0.669205, acc.: 64.06%] [G loss: 0.713878]\n",
            "13500 [D loss: 0.625406, acc.: 64.06%] [G loss: 0.793404]\n",
            "13800 [D loss: 0.565612, acc.: 76.56%] [G loss: 0.874551]\n",
            "14100 [D loss: 0.638417, acc.: 68.75%] [G loss: 0.912873]\n",
            "14400 [D loss: 0.528127, acc.: 76.56%] [G loss: 0.951651]\n",
            "14700 [D loss: 0.625208, acc.: 60.94%] [G loss: 0.925599]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGz9y-qn7Iy_"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}