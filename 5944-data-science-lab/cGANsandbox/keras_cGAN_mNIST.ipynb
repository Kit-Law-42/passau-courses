{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "keras_cGAN_mNIST.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9CVrFUTmcmv"
      },
      "source": [
        "### cGAN_Keras with MNIST data set as sample.\n",
        "Code get from  https://github.com/mabagheri/CGAN/blob/master/cgan_Keras.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWO7-LWPmcne"
      },
      "source": [
        "#### 1. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_ToRLO4mcnh"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation, Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical, plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-47df02df4bf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvanced_activations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo3wdc8cmcnl"
      },
      "source": [
        "#### 2. Define Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXF638Mpmcnm"
      },
      "source": [
        "class CGAN:\n",
        "    def __init__(self, img_width, img_height, n_channels, n_classes):\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.n_channels = n_channels\n",
        "        self.img_shape = (self.img_width, self.img_height, self.n_channels)\n",
        "        self.n_classes = n_classes\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator_model()\n",
        "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
        "                                   optimizer=optimizer,\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim, ))\n",
        "        label = Input(shape=(self.n_classes,))\n",
        "        img = self.generator([noise, label])\n",
        "\n",
        "        # during generator updating,  the discriminator is fixed (will not be updated).\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated image and label as input and determines its validity\n",
        "        validity = self.discriminator([img, label])\n",
        "\n",
        "        self.cgan_model = Model(inputs=[noise, label], outputs=validity) # https://github.com/keras-team/keras/issues/13743\n",
        "        self.cgan_model.compile(loss=['binary_crossentropy'],\n",
        "                                optimizer=optimizer,\n",
        "                                metrics=['accuracy'])\n",
        "\n",
        "        plot_model(self.cgan_model, show_shapes=True, to_file='cgan-adversarial_model.png')\n",
        "        plot_model(self.generator, show_shapes=True, to_file='cgan-generator_model.png')\n",
        "        plot_model(self.discriminator, show_shapes=True, to_file='cgan-discriminator.png')\n",
        "\n",
        "    def build_discriminator_model(self):\n",
        "\n",
        "        model_input = Input(shape=(self.img_width, self.img_height, self.n_channels), name='discriminator_input')\n",
        "\n",
        "        x = model_input\n",
        "\n",
        "        labels = Input(shape=(self.n_classes,))\n",
        "        # labels_embedded = Flatten()(Embedding(self.num_classes, self.latent_dim)(labels))\n",
        "        labels_embedded = Dense(self.img_width * self.img_width)(labels)\n",
        "        labels_embedded = Reshape((self.img_width, self.img_height, self.n_channels))(labels_embedded)\n",
        "\n",
        "        x = concatenate([x, labels_embedded])\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Conv2D(filters=256, kernel_size=5, strides=1, padding='same')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(1)(x)\n",
        "        x = Activation('sigmoid')(x)\n",
        "        # model_input is conditioned by labels\n",
        "        discriminator = Model([model_input, labels], x, name='discriminator')\n",
        "\n",
        "        return discriminator\n",
        "\n",
        "    def build_generator(self):\n",
        "        image_resize = self.img_height // 4\n",
        "\n",
        "        inputs = Input(shape=(self.latent_dim,), name='z_input')\n",
        "        labels = Input(shape=(self.n_classes,), name='class_labels')\n",
        "\n",
        "        x = concatenate([inputs, labels], axis=1)\n",
        "        x = Dense(image_resize * image_resize * 128)(x)\n",
        "        x = Reshape((image_resize, image_resize, 128))(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=32, kernel_size=5, strides=1, padding='same')(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=1, kernel_size=5, strides=1, padding='same')(x)\n",
        "\n",
        "        x = Activation('sigmoid')(x)\n",
        "        # input is conditioned by labels\n",
        "        generator = Model(inputs=[inputs, labels], outputs=x, name='generator') # https://github.com/keras-team/keras/issues/13743\n",
        "        return generator\n",
        "\n",
        "    def train(self, x_train, y_train, epochs=1000, batch_size=128, sample_interval=50):\n",
        "\n",
        "        x_train = np.reshape(x_train, [-1, self.img_width, self.img_height, self.n_channels])\n",
        "        x_train = x_train.astype('float32') / 255\n",
        "\n",
        "        y_train = to_categorical(y_train)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            #  --------------------- Train Discriminator ---------------------\n",
        "            # Select a random half batch of images\n",
        "            idx = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
        "            imgs, labels = x_train[idx], y_train[idx]\n",
        "\n",
        "            # Generate sample noise for generator input\n",
        "            noise = self.generate_noise(\"uniform_noise\", batch_size)\n",
        "\n",
        "            # Generate a half batch of new images\n",
        "            # we can use labels instead of fake_labels; because it is fake for noise\n",
        "            gen_imgs = self.generator.predict([noise, labels])\n",
        "\n",
        "            # --------------------- Train the Discriminator ---------------------\n",
        "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], real)\n",
        "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            #  --------------------- Train the Generator ---------------------\n",
        "            # Condition on labels (random one-hot labels)\n",
        "            fake_labels = np.eye(self.n_classes)[np.random.choice(self.n_classes, batch_size)]\n",
        "\n",
        "            # Train the generator\n",
        "            cgan_loss, acc = self.cgan_model.train_on_batch([noise, fake_labels], real)\n",
        "\n",
        "            # Plot the progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], cgan_loss))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch) # TO-DOm not working in google colab\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 2, 5\n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[r * c, self.latent_dim])\n",
        "\n",
        "        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
        "        sampled_labels_categorical = to_categorical(sampled_labels)\n",
        "\n",
        "        gen_imgs = self.generator.predict([noise, sampled_labels_categorical])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "                axs[i, j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
        "                axs[i, j].axis('off')\n",
        "                cnt += 1\n",
        "        images_dir = '/content/drive/My Drive/Images'\n",
        "        fig.savefig(f\"{images_dir}/mnist/%d.png\" % epoch, bbox_inches='tight', dpi=200)\n",
        "        plt.close()\n",
        "\n",
        "    def generate_noise(self, type_of_noise, batch_size):\n",
        "        if type_of_noise == \"normal_noise\":\n",
        "            return np.random.normal(0, 1, size=[batch_size, self.latent_dim])\n",
        "\n",
        "        elif type_of_noise == \"uniform_noise\":\n",
        "            return np.random.uniform(-1.0, 1.0, size=[batch_size, self.latent_dim])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr6g_8lemcn1"
      },
      "source": [
        "#### 3. main method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MpVK3jFLmcn-",
        "outputId": "ec76daed-9075-4259-b65e-b706247d6308"
      },
      "source": [
        "(X, y), (_, _) = mnist.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "if X[0].ndim == 3:\n",
        "    img_w, img_h, num_channels = X[0].shape\n",
        "else:\n",
        "    img_w, img_h = X[0].shape\n",
        "    num_channels = 1\n",
        "\n",
        "cgan = CGAN(img_w, img_h, num_channels, num_classes)\n",
        "\n",
        "cgan.train(X, y, epochs=12000, batch_size=32, sample_interval=300)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mnist' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-3-d19fdfa5a67b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimg_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'mnist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}